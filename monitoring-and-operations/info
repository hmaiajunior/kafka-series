OBS:. Tive falha para subir o ambiente através dos templates enviados, então irei seguir acompanhando o treinamento a partir de uma stack criada localmente com docker-compose. Os yamls encontra-se no diretório local chamado compose.

==> Seção preparando ambiente:

Após subir o ambiente com os templates do diretório code, logar na máquina do zookeeper e validar que o serviço está sendo executado normalmente com o comando abaixo:

sudo systemctl status zookeeper

Para verificar os logs:

journalctl -u zookeeper

Pode-se verificar as variáveis existentes no bach listando o conteúdo do arquivo bash_profile:

cat .bash_profile

É possível também abrir um cliente interativo (shell) que se conecta ao Zookeeper:

kafka/bin/zookeeper-shell.sh localhost:2181

Para verificar o arquivo de configuração do Zookeeper:

cat zookeeper.properties

Para validar os parâmetros de como o zookeeper é inicializado, pode-se verificar o arquivo de serviço do systemd:

cat /etc/systemd/system/zookeeper.service


Após validação do Zookeeper, vamos logar na máquina do kafka:

ssh -i monitoring-and-operations/pem/kafka.pem ec2-user@<ip-do-kafka>

O arquivo kafka.properties está localizado em:

Com o comando lsblk é possível verificar os discos anexados a instância do kafka e onde estão montados.

Os mesmo comandos de verificação do serviço do zookeeper podem ser utilizados para o kafka, alterando o nome do serviço para kafka.


Faça um teste de criaçao de um tópico:

kafka/bin/kafka-topics.sh --create --topic meu-topico --bootstrap-server localhost:29091 --partitions 3 --replication-factor 1

Agora valide se o tópico foi criado:

kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092

Para produzir mensagens no tópico criado:

kafka/bin/kafka-console-producer.sh --topic meu-topico --bootstrap-server localhost:29091

Para consumir as mensagens do tópico:

kafka/bin/kafka-console-consumer.sh --topic meu-topico --bootstrap-server localhost:29091 --from-beginning.


==> Seção administrando o Kafka:

Aqui iremos subir algumas ferramentas de administração do kafka, o zoonavigator, kafka manager e kafka monitor. Para iniciarmos subar uma instância EC2 com o sistema operacional Amazon Linux 2.

Agora, verifique os passos de instalação do Docker e Docker-compose no arquivo monitoring-and-operations/code/0-basic-admins-tools/admin-setup.sh

Instalado o Docker e o Docker-compose, vamos subir o zoonavigator:

Execute o yaml no diretório monitoring-and-operations/code/0-basic-admin-tools com o comando:
docker-compose -f zoonavigator.yml up -d

OBS: Executar o comando acima dentro da instância EC2 criada.

Após isso os passos para instalação das ferramentas de administração do Kafka estão no arquivo monitoring-and-operations/code/0-basic-admins-tools/admin-setup.sh

==> Seção monitorando o Kafka:

Por padrão o kafka expõe métricas via JMX na porta 9999. Para validar isso, logue na máquina do kafka e execute o comando:
netstat -tuln | grep 9999

Se a porta estiver aberta, você verá uma linha semelhante a esta:
tcp6       0      0 :::9999                 :::*                    LISTEN

Agora devemos baixar o java jmx exporter agent que será responsável por expor os JMX Beans via http para que o prometheus possa consumir.  Esse Java agent roda dentro da aplicação e coleta os valores JMX MBeans. Atente-se que o agent deve rodar dentro do kafka.










