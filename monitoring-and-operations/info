OBS:. Tive falha para subir o ambiente através dos templates enviados, então irei seguir acompanhando o treinamento a partir de uma stack criada localmente com docker-compose. Os yamls encontra-se no diretório local chamado compose.

==> Seção preparando ambiente:

Após subir o ambiente com os templates do diretório code, logar na máquina do zookeeper e validar que o serviço está sendo executado normalmente com o comando abaixo:

sudo systemctl status zookeeper

Para verificar os logs:

journalctl -u zookeeper

Pode-se verificar as variáveis existentes no bach listando o conteúdo do arquivo bash_profile:

cat .bash_profile

É possível também abrir um cliente interativo (shell) que se conecta ao Zookeeper:

kafka/bin/zookeeper-shell.sh localhost:2181

Para verificar o arquivo de configuração do Zookeeper:

cat zookeeper.properties

Para validar os parâmetros de como o zookeeper é inicializado, pode-se verificar o arquivo de serviço do systemd:

cat /etc/systemd/system/zookeeper.service


Após validação do Zookeeper, vamos logar na máquina do kafka:

ssh -i monitoring-and-operations/pem/kafka.pem ec2-user@<ip-do-kafka>

O arquivo kafka.properties está localizado em:

Com o comando lsblk é possível verificar os discos anexados a instância do kafka e onde estão montados.

Os mesmo comandos de verificação do serviço do zookeeper podem ser utilizados para o kafka, alterando o nome do serviço para kafka.


Faça um teste de criaçao de um tópico:

kafka/bin/kafka-topics.sh --create --topic meu-topico --bootstrap-server localhost:29091 --partitions 3 --replication-factor 1

Agora valide se o tópico foi criado:

kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092

Para produzir mensagens no tópico criado:

kafka/bin/kafka-console-producer.sh --topic meu-topico --bootstrap-server localhost:29091

Para consumir as mensagens do tópico:

kafka/bin/kafka-console-consumer.sh --topic meu-topico --bootstrap-server localhost:29091 --from-beginning.


==> Seção administrando o Kafka:

Aqui iremos subir algumas ferramentas de administração do kafka, o zoonavigator, kafka manager e kafka monitor. Para iniciarmos subar uma instância EC2 com o sistema operacional Amazon Linux 2.

Agora, verifique os passos de instalação do Docker e Docker-compose no arquivo monitoring-and-operations/code/0-basic-admins-tools/admin-setup.sh

Instalado o Docker e o Docker-compose, vamos subir o zoonavigator:

Execute o yaml no diretório monitoring-and-operations/code/0-basic-admin-tools com o comando:
docker-compose -f zoonavigator.yml up -d

OBS: Executar o comando acima dentro da instância EC2 criada.

Após isso os passos para instalação das ferramentas de administração do Kafka estão no arquivo monitoring-and-operations/code/0-basic-admins-tools/admin-setup.sh

==> Seção monitorando o Kafka:

Por padrão o kafka expõe métricas via JMX na porta 9999. Para validar isso, logue na máquina do kafka e execute o comando:
netstat -tuln | grep 9999

Se a porta estiver aberta, você verá uma linha semelhante a esta:
tcp6       0      0 :::9999                 :::*                    LISTEN

Agora devemos baixar o java jmx exporter agent que será responsável por expor os JMX Beans via http para que o prometheus possa consumir.  Esse Java agent roda dentro da aplicação e coleta os valores JMX MBeans. Atente-se que o agent deve rodar dentro do kafka.


==> Seção kafka operations:

Algumas operações no kafka, como o restart dos brokers por alguma necessidade específica, podem ser feitas de forma manual, porém é bem mais interessante realizar de forma automatizada. O kafka-utils da empresa Yelp pode ajudar com isso.

Baixe a ferramenta jolokia (agente http) e a coloque dentro de um diretório no broker
Agora será necessário adicionar um novo agent na variável KAFKA_OPTS:
    - "-javaagent:/home/ec2-user/jolokia/jolokia-jvm-2.3.0-javaagent.jar=host=*"

Atente-se para a alteração realizada no compose para que fosse possível a instalação do jq na imagem da confluent.

curl localhost:8778/jolokia

curl localhost:8778/jolokia/read/kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent | jq

curl localhost:8778/jolokia/read/kafka.server:name=UnderReplicatedPartitions,type=ReplicaManager/Value | jq



Algumas alterações nas configurações do kafka podem ser realizadas sem a necessidade do restart dos nodes. Na documentação (https://kafka.apache.org/38/documentation.html#brokerconfigs) é possível encontrar a lista de operações, conhecidas como Dynamic Update Mode, que irá indicar o modo do update que podem ser 3:

    - read-only: Requer o restart do broker
    - per-broker: Deve ser atualizada dinamicamente em cada um dos brokers
    - cluster-wide: Deve ser realizada dinamicamente usando a opção de cluster-wide


Com o comando abaixo é possível listar as configurações atribuídas dinamicamente:

==> kafka-configs --bootstrap-server localhost:9091 --entity-type brokers --entity-name 1 --describe

OBS:. Altere o entity-name de acordo com o broker em que estiver logado

Para alterar por exemplo o número de num.io.threads e num.network.threads, realize o comando abaixo em cada um dos brokers realizando as mudanças necessárias de acordo com o broker:

==> kafka-configs --bootstrap-server localhost:9091 --entity-type brokers -entity-name 1 --alter --add-config num.io.threads=16,num.network.threads=8


Para monitorar o num.io.thread via JMX procure pela métrica "RequestHandlerAvgIdlePercent"

Para monitorar o num.network.thread via JMX procure pela métrica "NetworkProcessorAvgIdlePercent"


==> Outra operação importante no kafka é a de rebalance que é quando as partições dos tópicos ficam distribuídas de forma desigual nos clusters. Para executar o balanceamento de forma manual é necessário fazer o seguinte:

    - Criar um plano de realocação:

        - kafka-reassign-partitions.sh \
        --bootstrap-server <broker> \
        --generate \
        --topics-to-move-json-file topics.json \
        --broker-list "1,2,3" \
        --replication-throttle 10485760

        O comando acima irá gerar um JSON com a distribuição atual e a proposta de nova distribuição de réplicas. Importante setar o replication-throttle para limitar o tráfego de replicação entre os brokers durante o rebalance e evitar o saturamento de rede e discos durante o processo.

        OBS: O arquivo topics.json é um arquivo json que contém o nome dos tópicos que vc quer trabalhar em cima deles.

    - Revise o plano gerado validando as partições que serão movidas, brokers que serão afetados e a possibilidade de sobrecarga.

    - Execute o plano:

        - kafka-reassign-partitions.sh \
        --bootstrap-server <broker> \
        --execute \
        --reassignment-json-file reassignment.json

    - Monitore o processo com o comando abaixo:

        - kafka-reassign-partitions.sh \
        --bootstrap-server <broker> \
        --verify \
        --reassignment-json-file reassignment.json



Essa é a forma manual, porém existem outras formas de realizar através de ferramentas como o kafka manager e o linkedIn tools.


=> Agora veremos como realizar o aumento do número de réplicas de partições de um determinado tópico. O processo pode ser feito também de forma manual utilizando o kafka-reassign-partitions.sh:

    - Crie o arquivo topics.json com os tópicos que contém as partições que vc quer aumentar o rf
    - Gere o plano com mesmo comando generate passado anteriormente
    - Após o plano ser gerado, edite o número de réplicas manualmente.
    - Execute o plano.
    - Acompanhe o plano.

OBS: Lebre-se de limitar o throughput para as réplicas entre os brokers para evitar saturamento de rede e discos.








